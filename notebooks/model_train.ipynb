{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5bd66ee",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "In this notebook, we will ask you a series of questions regarding model selection. Based on your responses, we will ask you to create the ML models that you've chosen. \n",
    "\n",
    "The bonus step is completely optional, but if you provide a sufficient third machine learning model in this project, we will add `1000` points to your Kahoot leaderboard score.\n",
    "\n",
    "**Note**: Use the dataset that you've created in your previous data transformation step (not the original model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b90a0",
   "metadata": {},
   "source": [
    "## Questions\n",
    "Is this a classification or regression task?  \n",
    "\n",
    "Answer here\n",
    "Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017bfb9f",
   "metadata": {},
   "source": [
    "Are you predicting for multiple classes or binary classes?  \n",
    "\n",
    "Answer here\n",
    "Binary: farud or not fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd9378",
   "metadata": {},
   "source": [
    "Given these observations, which 2 (or possibly 3) machine learning models will you choose?  \n",
    "\n",
    "List your models here\n",
    "Logistic regression for baseline and kNN using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c408b67",
   "metadata": {},
   "source": [
    "## First Model\n",
    "\n",
    "Using the first model that you've chosen, implement the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fab3d0",
   "metadata": {},
   "source": [
    "### 1) Create a train-test split\n",
    "\n",
    "Use your cleaned and transformed dataset to divide your features and labels into training and testing sets. Make sure youâ€™re only using numeric or properly encoded features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b0c646a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/miniconda3/envs/ds/lib/python3.12/site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/ds/lib/python3.12/site-packages (from xgboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/envs/ds/lib/python3.12/site-packages (from xgboost) (1.15.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "708cd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "transactions = pd.read_csv(\"../data/bank_transactions.csv\")\n",
    "transactions = transactions.drop(columns=[\"nameOrig\", \"nameDest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bbbfac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make balance difference columns for origin and destination \n",
    "transactions[\"origBalanceDiff\"] = (transactions[\"oldbalanceOrg\"] - transactions[\"newbalanceOrig\"])\n",
    "\n",
    "transactions[\"destBalanceDiff\"] = (transactions[\"newbalanceDest\"] - transactions[\"oldbalanceDest\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13817062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "categorical_features = [\"type\"]\n",
    "numerical_features = [\"amount\", \"origBalanceDiff\", \"destBalanceDiff\"]\n",
    "X = transactions[categorical_features + numerical_features]\n",
    "y = transactions[\"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c59568ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fedcd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# perform one-hot-encoding on a set of categorical columns\n",
    "\n",
    "# TODO: select your choice of categorical columns\n",
    "cat_features = transactions.select_dtypes(include=['object']).columns\n",
    "#cat_features = cat_features.drop([\"nameOrig\", \"nameDest\"])\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a5d8927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest', 'isFraud', 'isFlaggedFraud', 'origBalanceDiff',\n",
       "       'destBalanceDiff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                            \n",
    "#numerical columns\n",
    "num_features = transactions.select_dtypes(include=['int64', 'float64']).columns\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "494971c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASH_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CASH_OUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type\n",
       "0   PAYMENT\n",
       "1   PAYMENT\n",
       "2   CASH_IN\n",
       "3  TRANSFER\n",
       "4  CASH_OUT"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_cat = transactions[cat_features]\n",
    "X_num = transactions[num_features]\n",
    "\n",
    "X_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9657a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your machine learning model!\n",
    "# Split features and target\n",
    "X = transactions.select_dtypes(include=['int64', 'float64']).drop(columns=[\"isFraud\"])\n",
    "y = transactions['isFraud']\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c97f67",
   "metadata": {},
   "source": [
    "### 2) Search for best hyperparameters\n",
    "Use tools like GridSearchCV, RandomizedSearchCV, or model-specific tuning functions to find the best hyperparameters for your first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59c8fc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800000, 8), (200000, 8))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize features/ scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Return shape for confirmation\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30eee3",
   "metadata": {},
   "source": [
    "### 3) Train your model\n",
    "Select the model with best hyperparameters and generate predictions on your test set. Evaluate your models accuracy, precision, recall, and sensitivity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "228ed831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.6153846153846154\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00    199743\n",
      "    Is Fraud       0.85      0.48      0.62       257\n",
      "\n",
      "    accuracy                           1.00    200000\n",
      "   macro avg       0.92      0.74      0.81    200000\n",
      "weighted avg       1.00      1.00      1.00    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate model \n",
    "# logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg_model.predict(X_test_scaled)\n",
    "# F1-score and classification report\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Fraud\", \"Is Fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db128d64",
   "metadata": {},
   "source": [
    "## Second Model\n",
    "\n",
    "Create a second machine learning object and rerun steps (2) & (3) on this model. Compare accuracy metrics between these two models. Which handles the class imbalance more effectively?\n",
    "\n",
    "Create as many code-blocks as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "732baab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.720173535791757\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00    199743\n",
      "    Is Fraud       0.81      0.65      0.72       257\n",
      "\n",
      "    accuracy                           1.00    200000\n",
      "   macro avg       0.91      0.82      0.86    200000\n",
      "weighted avg       1.00      1.00      1.00    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, classification_report# Initated KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "# Fit the model on the training data\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "# F1-score and classification report\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_knn))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=[\"Not Fraud\", \"Is Fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66c411",
   "metadata": {},
   "source": [
    "### (Bonus/Optional) Third Model\n",
    "\n",
    "Create a third machine learning model and rerun steps (2) & (3) on this model. Which model has the best predictive capabilities? \n",
    "\n",
    "Create as many code-blocks as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d069e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /opt/miniconda3/envs/ds/lib/python3.12/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/miniconda3/envs/ds/lib/python3.12/site-packages (from imblearn) (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /opt/miniconda3/envs/ds/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (2.2.2)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /opt/miniconda3/envs/ds/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /opt/miniconda3/envs/ds/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /opt/miniconda3/envs/ds/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /opt/miniconda3/envs/ds/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /opt/miniconda3/envs/ds/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c44f6702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\