{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5bd66ee",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "In this notebook, we will ask you a series of questions regarding model selection. Based on your responses, we will ask you to create the ML models that you've chosen. \n",
    "\n",
    "The bonus step is completely optional, but if you provide a sufficient third machine learning model in this project, we will add `1000` points to your Kahoot leaderboard score.\n",
    "\n",
    "**Note**: Use the dataset that you've created in your previous data transformation step (not the original model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b90a0",
   "metadata": {},
   "source": [
    "## Questions\n",
    "Is this a classification or regression task?  \n",
    "\n",
    "Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017bfb9f",
   "metadata": {},
   "source": [
    "Are you predicting for multiple classes or binary classes?  \n",
    "\n",
    "Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd9378",
   "metadata": {},
   "source": [
    "Given these observations, which 2 (or possibly 3) machine learning models will you choose?  \n",
    "\n",
    "List your models here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c408b67",
   "metadata": {},
   "source": [
    "## First Model\n",
    "\n",
    "Using the first model that you've chosen, implement the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fab3d0",
   "metadata": {},
   "source": [
    "### 1) Create a train-test split\n",
    "\n",
    "Use your cleaned and transformed dataset to divide your features and labels into training and testing sets. Make sure youâ€™re only using numeric or properly encoded features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0c646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "708cd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "transactions = pd.read_csv(\"../data/bank_transactions.csv\")\n",
    "transactions = transactions.drop(columns=[\"nameOrig\", \"nameDest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fedcd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# perform one-hot-encoding on a set of categorical columns\n",
    "\n",
    "# TODO: select your choice of categorical columns\n",
    "cat_features = transactions.select_dtypes(include=['object']).columns\n",
    "#cat_features = cat_features.drop([\"nameOrig\", \"nameDest\"])\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5d8927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest', 'isFraud', 'isFlaggedFraud'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                            \n",
    "#numerical columns\n",
    "num_features = transactions.select_dtypes(include=['int64', 'float64']).columns\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "494971c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASH_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CASH_OUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type\n",
       "0   PAYMENT\n",
       "1   PAYMENT\n",
       "2   CASH_IN\n",
       "3  TRANSFER\n",
       "4  CASH_OUT"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_cat = transactions[cat_features]\n",
    "X_num = transactions[num_features]\n",
    "\n",
    "X_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9657a77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800000, 6), (200000, 6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement your machine learning model!\n",
    "# Split features and target\n",
    "X = transactions.select_dtypes(include=['int64', 'float64']).drop(columns=[\"isFraud\"])\n",
    "y = transactions['isFraud']\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Standardize features/ scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Return shape for confirmation\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cf489f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.5582655826558266\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00    199743\n",
      "    Is Fraud       0.92      0.40      0.56       257\n",
      "\n",
      "    accuracy                           1.00    200000\n",
      "   macro avg       0.96      0.70      0.78    200000\n",
      "weighted avg       1.00      1.00      1.00    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate model \n",
    "# logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg_model.predict(X_test_scaled)\n",
    "# F1-score and classification report\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Fraud\", \"Is Fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c97f67",
   "metadata": {},
   "source": [
    "### 2) Search for best hyperparameters\n",
    "Use tools like GridSearchCV, RandomizedSearchCV, or model-specific tuning functions to find the best hyperparameters for your first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8fc08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed30eee3",
   "metadata": {},
   "source": [
    "### 3) Train your model\n",
    "Select the model with best hyperparameters and generate predictions on your test set. Evaluate your models accuracy, precision, recall, and sensitivity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ed831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db128d64",
   "metadata": {},
   "source": [
    "## Second Model\n",
    "\n",
    "Create a second machine learning object and rerun steps (2) & (3) on this model. Compare accuracy metrics between these two models. Which handles the class imbalance more effectively?\n",
    "\n",
    "Create as many code-blocks as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "732baab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.7317073170731707\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00    199743\n",
      "    Is Fraud       0.85      0.64      0.73       257\n",
      "\n",
      "    accuracy                           1.00    200000\n",
      "   macro avg       0.93      0.82      0.87    200000\n",
      "weighted avg       1.00      1.00      1.00    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, classification_report# Initated KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "# Fit the model on the training data\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "# F1-score and classification report\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_knn))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=[\"Not Fraud\", \"Is Fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66c411",
   "metadata": {},
   "source": [
    "### (Bonus/Optional) Third Model\n",
    "\n",
    "Create a third machine learning model and rerun steps (2) & (3) on this model. Which model has the best predictive capabilities? \n",
    "\n",
    "Create as many code-blocks as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "svm_model = SVC(kernel='rbf')\n",
    "# Fit the model on the training data\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "# F1-score and classification report\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=[\"Not Fraud\", \"Is Fraud\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d069e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "sample = transactions.sample(10000)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fddd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split the data into features and labels, select 2 numerical columns\n",
    "X = sample[[\"oldbalanceOrg\", \"amount\"]]\n",
    "y = sample[\"isFraud\"]\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# train kNN on the imbalanced data\n",
    "knn_imb = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_imb.fit(X_train, y_train)\n",
    "\n",
    "yhat = knn_imb.predict(X_test)\n",
    "baseline_acc = accuracy_score(y_test, yhat)\n",
    "\n",
    "print(\"Baseline testing accuracy (imbalanced) (WOW AMAZING!):\", baseline_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a92702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to rebalance the training set (number of neighbors needs to be less than number of minority class samples)\n",
    "smote = SMOTE(k_neighbors=2, random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(y_train_smote.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain kNN on the balanced data\n",
    "knn_smote = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "yhat_pred = knn_smote.predict(X_test)\n",
    "smote_acc = accuracy_score(y_test, yhat_pred)\n",
    "\n",
    "print(\"Testing accuracy after applying SMOTE:\", smote_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
